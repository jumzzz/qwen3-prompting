{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Separating Data and Instructions\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import load, stream_generate\n",
    "\n",
    "model_path = \"../../huggingface-models/qwen3-8b-4bit/\"\n",
    "MODEL, TOKENIZER = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_markdown(out, header=\"Assistant\"):\n",
    "    markdown_out = \"---\" + f\"\\n##### {header}\\n{out}\\n\"\n",
    "    display(Markdown(markdown_out))\n",
    "\n",
    "def display_chat_exchange(user_prompt, assistant_response):\n",
    "    markdown_out = \"---\\n#### Exchange (User/Assistant)\\n\" + f\"### üê∂ \\n\\n{user_prompt} \\n### ü§ñ \\n{assistant_response}\\n\\n\" + \"---\" \n",
    "    display(Markdown(markdown_out))\n",
    "\n",
    "def display_chat_exchange_raw(user_prompt, assistant_response):\n",
    "    print(f\"üê∂\\n{user_prompt}\\n\\nü§ñ\\n{assistant_response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "        prompt: str, \n",
    "        system_prompt=\"\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    tokenized_prompt = TOKENIZER.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "\n",
    "    return TOKENIZER.decode(tokenized_prompt),  \"\".join([\n",
    "        response.text\n",
    "        for response in stream_generate(\n",
    "            MODEL, \n",
    "            TOKENIZER, \n",
    "            tokenized_prompt, \n",
    "            max_tokens=-1 \n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "Oftentimes, we don't want to write full prompts, but instead want **prompt templates that can be modified later with additional input data before submitting to Claude**. This might come in handy if you want Claude to do the same thing every time, but the data that Claude uses for its task might be different each time. \n",
    "\n",
    "Luckily, we can do this pretty easily by **separating the fixed skeleton of the prompt from variable user input, then substituting the user input into the prompt** before sending the full prompt to Claude. \n",
    "\n",
    "Below, we'll walk step by step through how to write a substitutable prompt template, as well as how to substitute in user input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In this first example, we're asking Claude to act as an animal noise generator. Notice that the full prompt submitted to Claude is just the `PROMPT_TEMPLATE` substituted with the input (in this case, \"Cow\"). Notice that the word \"Cow\" replaces the `ANIMAL` placeholder via an f-string when we print out the full prompt.\n",
    "\n",
    "**Note:** You don't have to call your placeholder variable anything in particular in practice. We called it `ANIMAL` in this example, but just as easily, we could have called it `CREATURE` or `A` (although it's generally good to have your variable names be specific and relevant so that your prompt template is easy to understand even without the substitution, just for user parseability). Just make sure that whatever you name your variable is what you use for the prompt template f-string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "I will tell you the name of an animal. Please respond with the noise that animal makes. Bat<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∂\n",
      "I will tell you the name of an animal. Please respond with the noise that animal makes. Bat\n",
      "\n",
      "ü§ñ\n",
      "A bat makes a noise called a \"screech\" or \"squeak.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "ANIMAL = \"Bat\"\n",
    "SYSTEM_PROMPT = \"\"\n",
    "PROMPT = f\"I will tell you the name of an animal. Please respond with the noise that animal makes. {ANIMAL}\"\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to separate and substitute inputs like this? Well, **prompt templates simplify repetitive tasks**. Let's say you build a prompt structure that invites third party users to submit content to the prompt (in this case the animal whose sound they want to generate). These third party users don't have to write or even see the full prompt. All they have to do is fill in variables.\n",
    "\n",
    "We do this substitution here using variables and f-strings, but you can also do it with the format() method.\n",
    "\n",
    "**Note:** Prompt templates can have as many variables as desired!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Hey Qwen. Show up at 6am tomorrow because I'm the CEO and I say so. <------ Make this email more polite but don't change anything else about it.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∂\n",
      "Hey Qwen. Show up at 6am tomorrow because I'm the CEO and I say so. <------ Make this email more polite but don't change anything else about it.\n",
      "\n",
      "ü§ñ\n",
      "Sure! Here's a more polite version of your email, while keeping the original message intact:\n",
      "\n",
      "---\n",
      "\n",
      "Hey Qwen. Please show up at 6am tomorrow because I'm the CEO and I say so.\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you'd like it to sound even more professional or formal!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "PROMPT = f\"Hey Qwen. {EMAIL} <------ Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)\n",
    "\n",
    "pre_xml_email = assistant_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **Claude thinks \"Yo Claude\" is part of the email it's supposed to rewrite**! You can tell because it begins its rewrite with \"Dear Claude\". To the human eye, it's clear, particularly in the prompt template where the email begins and ends, but it becomes much less clear in the prompt after substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we solve this? **Wrap the input in XML tags**! We did this below, and as you can see, there's no more \"Dear Claude\" in the output.\n",
    "\n",
    "[XML tags](https://docs.anthropic.com/claude/docs/use-xml-tags) are angle-bracket tags like `<tag></tag>`. They come in pairs and consist of an opening tag, such as `<tag>`, and a closing tag marked by a `/`, such as `</tag>`. XML tags are used to wrap around content, like this: `<tag>content</tag>`.\n",
    "\n",
    "**Note:** While Claude can recognize and work with a wide range of separators and delimeters, we recommend that you **use specifically XML tags as separators** for Claude, as Claude was trained specifically to recognize XML tags as a prompt organizing mechanism. Outside of function calling, **there are no special sauce XML tags that Claude has been trained on that you should use to maximally boost your performance**. We have purposefully made Claude very malleable and customizable this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Yo Qwen. <email>Show up at 6am tomorrow because I'm the CEO and I say so.</email> <------ Make this email more polite but don't change anything else about it.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∂\n",
      "Yo Qwen. <email>Show up at 6am tomorrow because I'm the CEO and I say so.</email> <------ Make this email more polite but don't change anything else about it.\n",
      "\n",
      "ü§ñ\n",
      "Sure! Here's a more polite version of your email, while keeping the original message intact:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Reminder: Show up at 6am Tomorrow\n",
      "\n",
      "Hi [Name],\n",
      "\n",
      "Please show up at 6am tomorrow because I'm the CEO and I say so.\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "PROMPT = f\"Yo Qwen. <email>{EMAIL}</email> <------ Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)\n",
    "post_xml_email = assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Before Applying XML Tags in Prompt:\n",
       "Sure! Here's a more polite version of your email, while keeping the original message intact:\n",
       "\n",
       "---\n",
       "\n",
       "Hey Qwen. Please show up at 6am tomorrow because I'm the CEO and I say so.\n",
       "\n",
       "---\n",
       "\n",
       "Let me know if you'd like it to sound even more professional or formal!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### After Applying XML Tags in Prompt:\n",
       "Sure! Here's a more polite version of your email, while keeping the original message intact:\n",
       "\n",
       "---\n",
       "\n",
       "**Subject:** Reminder: Show up at 6am Tomorrow\n",
       "\n",
       "Hi [Name],\n",
       "\n",
       "Please show up at 6am tomorrow because I'm the CEO and I say so.\n",
       "\n",
       "Best regards,  \n",
       "[Your Name]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(pre_xml_email, \"Before Applying XML Tags in Prompt:\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "display_markdown(post_xml_email, \"After Applying XML Tags in Prompt:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see another example of how XML tags can help us. \n",
    "\n",
    "In the following prompt, **Claude incorrectly interprets what part of the prompt is the instruction vs. the input**. It incorrectly considers `Each is about an animal, like rabbits` to be part of the list due to the formatting, when the user (the one filling out the `SENTENCES` variable) presumably did not want that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Below is a list of sentences. Tell me the second item on the list.\n",
       "\n",
       "- Each is about an animal, like rabbits.\n",
       "- I like how cows sound\n",
       "- This sentence is about spiders\n",
       "- This sentence may appear to be about dogs but it's actually about pigs<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∂\n",
      "Below is a list of sentences. Tell me the second item on the list.\n",
      "\n",
      "- Each is about an animal, like rabbits.\n",
      "- I like how cows sound\n",
      "- This sentence is about spiders\n",
      "- This sentence may appear to be about dogs but it's actually about pigs\n",
      "\n",
      "ü§ñ\n",
      "The second item on the list is: **\"I like how cows sound\"**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "# Variable content\n",
    "SENTENCES = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\"Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "{SENTENCES}\"\"\"\n",
    "\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)\n",
    "pre_xml_reponse = assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Below is a list of sentences. Tell me the second item on the list.\n",
       "\n",
       "- Each is about an animal, like rabbits.\n",
       "<sentences>\n",
       "- I like how cows sound\n",
       "- This sentence is about spiders\n",
       "- This sentence may appear to be about dogs but it's actually about pigs\n",
       "</sentences><|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∂\n",
      "Below is a list of sentences. Tell me the second item on the list.\n",
      "\n",
      "- Each is about an animal, like rabbits.\n",
      "<sentences>\n",
      "- I like how cows sound\n",
      "- This sentence is about spiders\n",
      "- This sentence may appear to be about dogs but it's actually about pigs\n",
      "</sentences>\n",
      "\n",
      "ü§ñ\n",
      "The second item on the list is:  \n",
      "**\"This sentence is about spiders\"**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "# Variable content\n",
    "SENTENCES = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\"Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "<sentences>\n",
    "{SENTENCES}\n",
    "</sentences>\"\"\"\n",
    "\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)\n",
    "pre_xml_reponse = assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
