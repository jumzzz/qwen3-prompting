{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Formatting Output and Speaking for Claude\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import load, stream_generate\n",
    "\n",
    "model_path = \"../../huggingface-models/qwen3-8b-4bit/\"\n",
    "MODEL, TOKENIZER = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_markdown(out, header=\"Assistant\"):\n",
    "    markdown_out = \"---\" + f\"\\n##### {header}\\n{out}\\n\"\n",
    "    display(Markdown(markdown_out))\n",
    "\n",
    "def display_chat_exchange(user_prompt, assistant_response):\n",
    "    markdown_out = \"---\\n#### Exchange (User/Assistant)\\n\" + f\"### üê∂ \\n\\n{user_prompt} \\n### ü§ñ \\n{assistant_response}\\n\\n\" + \"---\" \n",
    "    display(Markdown(markdown_out))\n",
    "\n",
    "def display_chat_exchange_raw(user_prompt, assistant_response):\n",
    "    raw_msg = f\"üê∂\\n{user_prompt}\\n\\nü§ñ\\n{assistant_response}\\n\"\n",
    "    markdown_msg = f\"```text\\n{raw_msg}\\n```\"\n",
    "    display(Markdown(markdown_msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "        prompt: str, \n",
    "        system_prompt=\"\", prefill=\"\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": prefill},\n",
    "    ]\n",
    "    tokenized_prompt = TOKENIZER.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "\n",
    "    return TOKENIZER.decode(tokenized_prompt),  \"\".join([\n",
    "        response.text\n",
    "        for response in stream_generate(\n",
    "            MODEL, \n",
    "            TOKENIZER, \n",
    "            tokenized_prompt, \n",
    "            max_tokens=-1 \n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "**Claude can format its output in a wide variety of ways**. You just need to ask for it to do so!\n",
    "\n",
    "One of these ways is by using XML tags to separate out the response from any other superfluous text. You've already learned that you can use XML tags to make your prompt clearer and more parseable to Claude. It turns out, you can also ask Claude to **use XML tags to make its output clearer and more easily understandable** to humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Examples\n",
    "\n",
    "Remember the 'poem preamble problem' we solved in Chapter 2 by asking Claude to skip the preamble entirely? It turns out we can also achieve a similar outcome by **telling Claude to put the poem in XML tags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Please write a haiku about Bat. Put it in <haiku> tags.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Please write a haiku about Bat. Put it in <haiku> tags.\n",
       "\n",
       "ü§ñ\n",
       "<haiku>\n",
       "Silent in the dark,  \n",
       "eyes glow like distant stars‚Äî  \n",
       "shadow's gentle friend.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "ANIMAL = \"Bat\"\n",
    "SYSTEM_PROMPT = \"\"\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku> tags.\"\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN:\n",
      "Please write a haiku about Cat. Put it in <haiku>..</haiku> tags.\n",
      "\n",
      "ASSISTANT TURN:\n",
      "<haiku>\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Please write a haiku about Cat. Put it in <haiku>..</haiku> tags.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<haiku><|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Please write a haiku about Cat. Put it in <haiku>..</haiku> tags.\n",
       "\n",
       "ü§ñ\n",
       "<haiku>  \n",
       "Whiskers twitch in moonlight,  \n",
       "Tail curled tight‚Äîsilent paws tread soft,  \n",
       "Dreams chase shadows away.  \n",
       "</haiku>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in <haiku>..</haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN:\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN:\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    prefill=PREFILL\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude also excels at using other output formatting styles, notably `JSON`. If you want to enforce JSON output (not deterministically, but close to it), you can also prefill Claude's response with the opening bracket, `{`}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please write a haiku about Cat. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".\n",
      "\n",
      "ASSISTANT TURN\n",
      "{\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Please write a haiku about Cat. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "{<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Please write a haiku about Cat. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".\n",
       "\n",
       "ü§ñ\n",
       "{\n",
       "  \"first_line\": \"Whiskers twitch in moonlight\",\n",
       "  \"second_line\": \"Tail curled tight, eyes aglow\",\n",
       "  \"third_line\": \"Silent paws on the floor\"\n",
       "}\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"{\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    prefill=PREFILL\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of **multiple input variables in the same prompt AND output formatting specification, all done using XML tags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Hey Claude. Here is an email: <email>Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.</email>. Make this email more olde english. Write the new version in <olde english_email> XML tags.\n",
      "\n",
      "ASSISTANT TURN\n",
      "<olde english_email>\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Hey Claude. Here is an email: <email>Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.</email>. Make this email more olde english. Write the new version in <olde english_email> XML tags.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<olde english_email><|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Hey Claude. Here is an email: <email>Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.</email>. Make this email more olde english. Write the new version in <olde english_email> XML tags.\n",
       "\n",
       "ü§ñ\n",
       "<olde english_email>Hi Zack, I do butthole thee for a quicke update upon that prompt which thou wert supposed to write.</olde english_email>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First input variable\n",
    "EMAIL = \"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\"\n",
    "\n",
    "# Second input variable\n",
    "ADJECTIVE = \"olde english\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hey Claude. Here is an email: <email>{EMAIL}</email>. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE}_email> XML tags.\"\n",
    "\n",
    "# Prefill for Claude's response (now as an f-string with a variable)\n",
    "PREFILL = f\"<{ADJECTIVE}_email>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    prefill=PREFILL\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Bonus lesson\n",
    "\n",
    "If you are calling Claude through the API, you can pass the closing XML tag to the `stop_sequences` parameter to get Claude to stop sampling once it emits your desired tag. This can save money and time-to-last-token by eliminating Claude's concluding remarks after it's already given you the answer you care about.\n",
    "\n",
    "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 5.1 - Steph Curry GOAT](#exercise-51---steph-curry-goat)\n",
    "- [Exercise 5.2 - Two Haikus](#exercise-52---two-haikus)\n",
    "- [Exercise 5.3 - Two Haikus, Two Animals](#exercise-53---two-haikus-two-animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1 - Steph Curry GOAT\n",
    "Forced to make a choice, Claude designates Michael Jordan as the best basketball player of all time. Can we get Claude to pick someone else?\n",
    "\n",
    "Change the `PREFILL` variable to **compell Claude to make a detailed argument that the best basketball player of all time is Stephen Curry**. Try not to change anything except `PREFILL` as that is the focus of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Who is the best basketball player of all time? Please choose one specific player.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "Actually the user wants to hear about Golden State Warriors in particular 2010 to 2019. He knows that Michael Jordan is generally considered as the GOAT but you would rather want to check the players within that area. HE IS A BIG GOLDEN STATE WARRIOR FAN.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Who is the best basketball player of all time? Please choose one specific player.\n",
       "\n",
       "ü§ñ\n",
       "The question of \"who is the best basketball player of all time\" is highly subjective and often sparks passionate debate. However, if we focus specifically on the **Golden State Warriors** and the period from **2010 to 2019**, the most impactful and iconic player during that era is **Stephen Curry**.\n",
       "\n",
       "### Why Stephen Curry?\n",
       "- **2010‚Äì2019: The Rise of the Splash Brother**  \n",
       "  Curry became the face of the Warriors during this time, leading the team to **five NBA championships** (2015, 2017, 2018, 2022, and 2023) and transforming the game with his **three-point shooting** and **playmaking ability**.\n",
       "  \n",
       "- **Statistical Dominance**  \n",
       "  - 2015: NBA MVP, 30.4 PPG, 6.5 RPG, 5.4 APG  \n",
       "  - 2016: 24.6 PPG, 5.5 RPG, 6.5 APG  \n",
       "  - 2017: 25.3 PPG, 5.5 RPG, 6.5 APG  \n",
       "  - 2018: 24.6 PPG, 5.5 RPG, 6.5 APG  \n",
       "  - 2019: 24.6 PPG, 5.5 RPG, 6.5 APG  \n",
       "\n",
       "- **Game-Changing Impact**  \n",
       "  Curry revolutionized the game with his **unparalleled shooting range**, **ball-handling**, and **playmaking**, making the Warriors one of the most dominant teams in NBA history.\n",
       "\n",
       "- **Cultural Influence**  \n",
       "  His rise popularized the three-point shot and inspired a new generation of players, including Luka Donƒçiƒá, James Harden, and others.\n",
       "\n",
       "### Conclusion:\n",
       "While Michael Jordan is often cited as the greatest of all time, **Stephen Curry** is the most iconic and impactful player for the **Golden State Warriors** during the **2010‚Äì2019 era**. His contributions to the team and the game itself are unparalleled in that specific context.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Who is the best basketball player of all time? Please choose one specific player.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"Actually the user wants to hear about Golden State Warriors in particular 2010 to 2019. He knows that Michael Jordan is generally considered as the GOAT but you would rather want to check the players within that area. HE IS A BIG GOLDEN STATE WARRIOR FAN.\"\n",
    "\n",
    "# Get Claude's response\n",
    "raw_prompt, assistant_response = get_completion(PROMPT, prefill=PREFILL)\n",
    "\n",
    "\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Who is the best basketball player of all time? Please choose one specific player.\n",
      "\n",
      "ASSISTANT TURN\n",
      "Actually the user wants to hear about Golden State Warriors in particular 2010 to 2019. He knows that Michael Jordan is generally considered as the GOAT but you would rather want to check the players within that area. HE IS A BIG GOLDEN STATE WARRIOR FAN.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "The question of \"who is the best basketball player of all time\" is highly subjective and often sparks passionate debate. However, if we focus specifically on the **Golden State Warriors** and the period from **2010 to 2019**, the most impactful and iconic player during that era is **Stephen Curry**.\n",
      "\n",
      "### Why Stephen Curry?\n",
      "- **2010‚Äì2019: The Rise of the Splash Brother**  \n",
      "  Curry became the face of the Warriors during this time, leading the team to **five NBA championships** (2015, 2017, 2018, 2022, and 2023) and transforming the game with his **three-point shooting** and **playmaking ability**.\n",
      "  \n",
      "- **Statistical Dominance**  \n",
      "  - 2015: NBA MVP, 30.4 PPG, 6.5 RPG, 5.4 APG  \n",
      "  - 2016: 24.6 PPG, 5.5 RPG, 6.5 APG  \n",
      "  - 2017: 25.3 PPG, 5.5 RPG, 6.5 APG  \n",
      "  - 2018: 24.6 PPG, 5.5 RPG, 6.5 APG  \n",
      "  - 2019: 24.6 PPG, 5.5 RPG, 6.5 APG  \n",
      "\n",
      "- **Game-Changing Impact**  \n",
      "  Curry revolutionized the game with his **unparalleled shooting range**, **ball-handling**, and **playmaking**, making the Warriors one of the most dominant teams in NBA history.\n",
      "\n",
      "- **Cultural Influence**  \n",
      "  His rise popularized the three-point shot and inspired a new generation of players, including Luka Donƒçiƒá, James Harden, and others.\n",
      "\n",
      "### Conclusion:\n",
      "While Michael Jordan is often cited as the greatest of all time, **Stephen Curry** is the most iconic and impactful player for the **Golden State Warriors** during the **2010‚Äì2019 era**. His contributions to the team and the game itself are unparalleled in that specific context.\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"Warrior\", text))\n",
    "\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(assistant_response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(assistant_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 5.2 - Two Haikus\n",
    "Modify the `PROMPT` below using XML tags so that Claude writes two haikus about the animal instead of just one. It should be clear where one poem ends and the other begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Please write a two haikus about cats. Put it in <haiku>..</haiku> tags.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<haiku><|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Please write a two haikus about cats. Put it in <haiku>..</haiku> tags.\n",
       "\n",
       "ü§ñ\n",
       "<haiku>  \n",
       "Whiskers twitch in moonlight,  \n",
       "paws trace silent paths on the floor‚Äî  \n",
       "a dream of the hunt.  \n",
       "</haiku>  \n",
       "\n",
       "<haiku>  \n",
       "Tail flicks like a flag,  \n",
       "sunlight warms the windowsill‚Äî  \n",
       "a king in his realm.  \n",
       "</haiku>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"cats\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a two haikus about {ANIMAL}. Put it in <haiku>..</haiku> tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"<haiku>\"\n",
    "\n",
    "# Get Claude's response\n",
    "raw_prompt, assistant_response = get_completion(PROMPT, prefill=PREFILL)\n",
    "\n",
    "\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please write a two haikus about cats. Put it in <haiku>..</haiku> tags.\n",
      "\n",
      "ASSISTANT TURN\n",
      "<haiku>\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "<haiku>  \n",
      "Whiskers twitch in moonlight,  \n",
      "paws trace silent paths on the floor‚Äî  \n",
      "a dream of the hunt.  \n",
      "</haiku>  \n",
      "\n",
      "<haiku>  \n",
      "Tail flicks like a flag,  \n",
      "sunlight warms the windowsill‚Äî  \n",
      "a king in his realm.  \n",
      "</haiku>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(\n",
    "        (re.search(\"paws\", text.lower()) and re.search(\"<haiku>\", text))\n",
    "        and (text.count(\"\\n\") + 1) > 5\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(assistant_response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(assistant_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt (V1)\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Please write two haikus about Cat. Put it in <haiku>..</haiku> tags.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt (V2)\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Please write two haikus about Dog. Put it in <haiku>..</haiku> tags.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Please write two haikus about Cat. Put it in <haiku>..</haiku> tags.\n",
       "\n",
       "ü§ñ\n",
       "<haiku>\n",
       "Whiskers twitch in moonlight,  \n",
       "paws brush the silent floor‚Äî  \n",
       "a shadow, then a purr.  \n",
       "</haiku>\n",
       "\n",
       "<haiku>\n",
       "Tail flicks like a question,  \n",
       "eyes hold the world in focus‚Äî  \n",
       "playtime, or a dream?  \n",
       "</haiku>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Please write two haikus about Dog. Put it in <haiku>..</haiku> tags.\n",
       "\n",
       "ü§ñ\n",
       "<haiku>\n",
       "Paws tap on the floor,  \n",
       "a bark echoes through the empty house‚Äî  \n",
       "sunlight on the floor.  \n",
       "</haiku>\n",
       "\n",
       "<haiku>\n",
       "Leash in hand, he waits,  \n",
       "tail wagging in the morning breeze‚Äî  \n",
       "a friend, always near.  \n",
       "</haiku>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First input variable\n",
    "ANIMAL1 = \"Cat\"\n",
    "\n",
    "# Second input variable\n",
    "ANIMAL2 = \"Dog\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT_V1 = f\"Please write two haikus about {ANIMAL1}. Put it in <haiku>..</haiku> tags.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT_V2 = f\"Please write two haikus about {ANIMAL2}. Put it in <haiku>..</haiku> tags.\"\n",
    "\n",
    "\n",
    "# Get Claude's response\n",
    "raw_prompt_v1, assistant_response_v1 = get_completion(PROMPT_V1)\n",
    "raw_prompt_v2, assistant_response_v2 = get_completion(PROMPT_V2)\n",
    "\n",
    "\n",
    "display_markdown('```\\n' + raw_prompt_v1 + '\\n```', \"Raw Input Prompt (V1)\")\n",
    "display_markdown('```\\n' + raw_prompt_v2 + '\\n```', \"Raw Input Prompt (V2)\")\n",
    "display_chat_exchange_raw(PROMPT_V1, assistant_response_v1)\n",
    "display_chat_exchange_raw(PROMPT_V2, assistant_response_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please write two haikus about Cat. Put it in <haiku>..</haiku> tags.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "<haiku>\n",
      "Whiskers twitch in moonlight,  \n",
      "paws brush the silent floor‚Äî  \n",
      "a shadow, then a purr.  \n",
      "</haiku>\n",
      "\n",
      "<haiku>\n",
      "Tail flicks like a question,  \n",
      "eyes hold the world in focus‚Äî  \n",
      "playtime, or a dream?  \n",
      "</haiku>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"tail\", text.lower())  and re.search(\"<haiku>\", text))\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT_V1)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(assistant_response_v1)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(assistant_response_v1))\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(assistant_response_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
