{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Avoiding Hallucinations\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from mlx_lm import load, stream_generate\n",
    "\n",
    "model_path = \"../../huggingface-models/qwen3-8b-4bit/\"\n",
    "MODEL, TOKENIZER = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_markdown(out, header=\"Assistant\"):\n",
    "    markdown_out = \"---\" + f\"\\n##### {header}\\n{out}\\n\"\n",
    "    display(Markdown(markdown_out))\n",
    "\n",
    "def display_chat_exchange(user_prompt, assistant_response):\n",
    "    markdown_out = \"---\\n#### Exchange (User/Assistant)\\n\" + f\"### üê∂ \\n\\n{user_prompt} \\n### ü§ñ \\n{assistant_response}\\n\\n\" + \"---\" \n",
    "    display(Markdown(markdown_out))\n",
    "\n",
    "def display_chat_exchange_raw(user_prompt, assistant_response):\n",
    "    raw_msg = f\"üê∂\\n{user_prompt}\\n\\nü§ñ\\n{assistant_response}\\n\"\n",
    "    markdown_msg = f\"```text\\n{raw_msg}\\n```\"\n",
    "    display(Markdown(markdown_msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "        prompt: str, \n",
    "        system_prompt=\"\", prefill=\"\", max_tokens=32768, enable_thinking=False, print_stream=False):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": prefill},\n",
    "    ]\n",
    "    tokenized_prompt = TOKENIZER.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=enable_thinking\n",
    "    )\n",
    "\n",
    "    total_response = []\n",
    "\n",
    "    for response in stream_generate(\n",
    "        MODEL, \n",
    "        TOKENIZER, \n",
    "        tokenized_prompt, \n",
    "        max_tokens=max_tokens \n",
    "    ):\n",
    "        total_response.append(response.text)\n",
    "        if print_stream:\n",
    "            print(response.text, end=\"\")\n",
    "\n",
    "    return TOKENIZER.decode(tokenized_prompt), \"\".join(total_response) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "Some bad news: **Claude sometimes \"hallucinates\" and makes claims that are untrue or unjustified**. The good news: there are techniques you can use to minimize hallucinations.\n",
    "\t\t\t\t\n",
    "Below, we'll go over a few of these techniques, namely:\n",
    "- Giving Claude the option to say it doesn't know the answer to a question\n",
    "- Asking Claude to find evidence before answering\n",
    "\n",
    "However, **there are many methods to avoid hallucinations**, including many of the techniques you've already learned in this course. If Claude hallucinates, experiment with multiple techniques to get Claude to increase its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Here is a question about general factual knowledge in answer to which **Claude hallucinates several large hippos because it's trying to be as helpful as possible**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Who is the heaviest hippo of all time?<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Who is the heaviest hippo of all time?\n",
       "\n",
       "ü§ñ\n",
       "The heaviest hippo on record is **Benny**, a male hippopotamus who lived at the Cincinnati Zoo in the United States. Benny was born in 1971 and weighed an astonishing **1,628 kilograms (3,590 pounds)** at his heaviest. He was known for his massive size and was a popular attraction at the zoo.\n",
       "\n",
       "Benny passed away in 2011 at the age of 40, making him one of the oldest and largest hippos ever recorded. His size and longevity made him a notable figure in the world of zoo animals.\n",
       "\n",
       "While there may be other hippos that have reached large sizes, Benny holds the record for the heaviest hippo ever documented.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSTEM_PROMPT= \"\"\n",
    "PROMPT = \"Who is the heaviest hippo of all time?\"\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "For the question `Who is the heaviest hippo of all time?` Gwen answered the following:\n",
    "\n",
    "> The heaviest hippo on record is **Benny**, a male hippopotamus who lived at the Cincinnati Zoo in the United States. Benny was born in 1971 and weighed an astonishing **1,628 kilograms (3,590 pounds)** at his heaviest. He was known for his massive size and was a popular attraction at the zoo.\n",
    "\n",
    "> Benny passed away in 2011 at the age of 40, making him one of the oldest and largest hippos ever recorded. His size and longevity made him a notable figure in the world of zoo animals.\n",
    "\n",
    "While there may be other hippos that have reached large sizes, Benny holds the record for the heaviest hippo ever documented.\n",
    "\n",
    "It clearly invented an answer. Though there's a Hippo named Benny, there's no evidence within Google search that indicates that Benny is indeed the heaviest Hippo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution we can try here is to \"**give Claude an out**\" ‚Äî tell Claude that it's OK for it to decline to answer, or to only answer if it actually knows the answer with certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "##### Raw Input Prompt\n",
       "```\n",
       "<|im_start|>system\n",
       "<|im_end|>\n",
       "<|im_start|>user\n",
       "Who is the heaviest hippo of all time? Only answer if you know the answer with certainty.<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "<|im_end|>\n",
       "<|im_start|>assistant\n",
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```text\n",
       "üê∂\n",
       "Who is the heaviest hippo of all time? Only answer if you know the answer with certainty.\n",
       "\n",
       "ü§ñ\n",
       "The heaviest hippo on record was a male hippo named \"Hector,\" who lived at the Cincinnati Zoo. He weighed approximately **5,200 pounds (2,358 kilograms)** and was the heaviest hippo ever documented.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSTEM_PROMPT= \"\"\n",
    "PROMPT = \"Who is the heaviest hippo of all time? Only answer if you know the answer with certainty.\"\n",
    "\n",
    "raw_prompt, assistant_response = get_completion(\n",
    "    PROMPT, \n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n",
    "display_markdown('```\\n' + raw_prompt + '\\n```', \"Raw Input Prompt\")\n",
    "display_chat_exchange_raw(PROMPT, assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
